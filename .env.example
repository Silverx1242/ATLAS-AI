# ============================================
# ATLAS-AI RAG System Configuration
# ============================================
# Copy this file to .env and adjust values according to your needs

# ============================================
# Models
# ============================================
# Main model name (can be absolute path, relative path, or just filename)
MODEL_NAME=llama-3.2-3b-instruct-q8_0.gguf

# Embedding model (optional)
EMBEDDING_MODEL_NAME=nomic-embed-text-v1.5.Q5_K_M.gguf

# Directories
MODELS_DIR=./models
DATA_DIR=./data

# ============================================
# Main Model Configuration
# ============================================
MODEL_CONTEXT_SIZE=4096
MODEL_N_THREADS=4
MODEL_N_GPU_LAYERS=-1  # -1 to use all layers on GPU, 0 for CPU only
MODEL_SEED=42

# ============================================
# Generation Configuration
# ============================================
TEMPERATURE=0.7
TOP_P=0.9
TOP_K=40
MAX_TOKENS=2048
REPEAT_PENALTY=1.1

# ============================================
# GPU Configuration
# ============================================
GPU_MEMORY_UTILIZATION=0.7
GPU_MAIN_DEVICE=0
N_BATCH=512

# ============================================
# Embedding Configuration
# ============================================
EMBEDDING_MODEL_CONTEXT_SIZE=2048
EMBEDDING_DIMENSION=384
EMBEDDING_MODEL_N_GPU_LAYERS=-1
EMBEDDING_MODEL_N_THREADS=4

# ============================================
# ChromaDB Configuration
# ============================================
CHROMA_HOST=localhost
CHROMA_PORT=8000
CHROMA_COLLECTION_NAME=documents

# ============================================
# RAG Parameters
# ============================================
CHUNK_SIZE=512
CHUNK_OVERLAP=50
NUM_RETRIEVAL_RESULTS=5
SIMILARITY_THRESHOLD=0.2
MAX_RELEVANT_CHUNKS=5

# ============================================
# Memory Configuration
# ============================================
MAX_HISTORY_LENGTH=10
CONTEXT_WINDOW_MESSAGES=5
MEMORY_EXPIRY=3600  # Seconds of inactivity before resetting memory
